# -*- coding: utf-8 -*-
"""COFLU_Scorer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-R33us5h2JYy5UeAb8-qu1hnn0JkO6Pd
"""

# Install the datasets dependencies
!pip install datasets

# Install from source will allow to make changes
!git clone https://github.com/huggingface/datasets.git
!sleep 60
!cd datasets
!pip install -e .
!python setup.py
!pip install sentencepiece


# Install transformers libraries
!pip install transformers

# Rouge scorer
!pip install rouge_score
from datasets import load_metric

# Module to calculate regular statistics
import statistics

"""# New Section"""

# The packages require Pytorch(1.0+) and TensorFlow (2.2+)
import tensorflow as tf
print(tf.__version__)
import torch 
print(torch.__version__)

# pretty print
import pprint

# Import a tokenizer associated with the model
from transformers import PegasusTokenizer, TFPegasusForConditionalGeneration

# Once a datasets is installed
# Configs and datasets can be loaded

from datasets import load_dataset
from datasets import get_dataset_config_names

# configs = get_dataset_config_names("cnn_dailymail")
# print(configs)

# Select newst config --> 3.0.0
dataset = load_dataset('cnn_dailymail', '3.0.0', split='test')

ARTICLE_TO_SUMMARIZE = (
dataset[0:2]['article']
)

model = TFPegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')
tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')
batch = tokenizer(ARTICLE_TO_SUMMARIZE, truncation=True, padding='longest', return_tensors="tf")
translated = model.generate(**batch,  return_dict_in_generate=True, num_beams= 5, top_k=3, min_length=50 )

# inputs = tokenizer(ARTICLE_TO_SUMMARIZE, max_length=1024, return_tensors='tf')

# Generate Summary

predictions = tokenizer.batch_decode(translated[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)

predictions

# Load metric
# First rouge

# rouge = load_metric('rouge')
coflu = load_metric('datasets/metrics/coflu')

# print(rouge.inputs_description)
print(coflu.inputs_description)

pp = pp= pprint.PrettyPrinter(indent=4, depth=5)
gold_summaries = dataset[0:2]['highlights']
# rouge = datasets.load_metric('rouge')
results = coflu.compute(predictions=predictions, references=gold_summaries, weights=[.5,.5])
# pp.pprint(list(results.keys()))

# results = coflu.compute(predictions=predictions, references=dataset[0:2]['highlights'], use_stemmer=True, use_agregator=True)
pp.pprint(results)

mean_rouge_sentence = statistics.mean([results['rouge1'].mid.recall, 
                  results['rouge2'].mid.recall, 
                  results['rougeL'].mid.recall])

mean_rouge_summary = results['rougeLsum'].mid.recall

print(f"Mean rouge (1,2,L) = {mean_rouge_sentence}")
print(f"Mean rouge (LSum) = {mean_rouge_summary}")