# -*- coding: utf-8 -*-
"""MetricAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1slPfUzvELtZPg9S3GZXhroilTNsFswAu

# NLP With Deep Learning (W266)

Submission by *Carolina Arriaga, Ayman, Abhi Sharma*

Winter 2021 | UC Berkeley

# Utils
"""

import datetime
from google.colab import files

def write_to_csv(df, inner_filename):
  now = datetime.datetime.now()
  filename = now.strftime("%Y-%m-%d-%H-%M-%S")

  compression_opts = dict(method='zip', archive_name='{}.csv'.format(inner_filename))

  df.to_csv('{}.zip'.format(filename), index=False, compression = compression_opts)
  files.download('{}.zip'.format(filename))

"""# Data Prep"""

import pandas as pd

# need upload file (drive/data)
scored = pd.read_csv('/content/data_scored_with_top_tranmatrix.csv')
scored.rename(columns={'story_id':'id'}, inplace=True)

summeval = pd.read_csv('/content/summeval_scores.csv')
summeval = summeval[summeval['model_id'] != 'M23_dynamicmix']

merged = pd.merge(scored, summeval, on=['id', 'model_id'])

len(merged)

merged.rename(columns={'decoded_x':'decoded'}, inplace=True)
merged = merged.drop(['decoded_y'], axis=1)

pearson = merged.corr(method ='pearson')
kendall = merged.corr(method ='kendall')

write_to_csv(pearson, 'pearson')

# sleep to avoid zip filenames being the same
!sleep 5

write_to_csv(kendall, 'kendall')

pearson.head()

"""# Column Wise Analysis"""

def get_corr(df, col1, col2, verbose=True):
  cor = df[col1].corr(df[col2])
  if verbose:
    print ("Correlation between {} and {} is {}".format(col1, col2, cor))
  return col1, col2, cor

def get_corrs(df, fixed_col):
  cols = list(df.columns)
  res = []
  for c in cols:
    # cant do correlations against string
    if isinstance(df[c][0], str) or isinstance(df[fixed_col][0], str):
      continue

    col1, col2, cor = get_corr(df, c, fixed_col, verbose=False)
    res.append({'col1': col1, 'col2': col2, 'pearson_corr': cor})
  return res    

def get_corrs_threshold(df, fixed_col, threshold=0.5, above=True):
  res = get_corrs(df, fixed_col)
  if above:
    res = [r for r in res if r['pearson_corr'] >= threshold]
  else:
    res = [r for r in res if r['pearson_corr'] <= threshold]
  return res

def get_expert_turk_cols():
  expert_turk_cols = [col for col in list(merged.columns) if 'expert' in col or 'turk' in col]
  expert_turk_cols = [col for col in expert_turk_cols if 'annotation' not in col]
  return expert_turk_cols

def get_non_expert_turk_cols():
  expert_turk_cols = [col for col in list(merged.columns) if 'expert' in col or 'turk' in col]
  return [c for c in list(merged.columns) if c not in expert_turk_cols]

"""Sanity Check"""

get_corr(merged, "turker_annotations_2_coherence", "turk_2_coherence")
get_corr(merged, "turker_annotations_3_fluency", "turk_3_fluency")
get_corr(merged, "expert_annotations_0_consistency", "expert_0_consistency")
get_corr(merged, "expert_annotations_1_relevance", "expert_1_relevance")

get_corrs_threshold(merged, 'expert_annotations_0_consistency', threshold=0.7, above=True)

"""Iterate over expert and turker scores to see if any of them correlate with a real feature"""

aggregated_corrs_et = []
et_cols = get_expert_turk_cols()
for c in et_cols:
  aggregated_corrs_et.extend(get_corrs_threshold(merged, c, threshold=0.25))

# filter self correlations
aggregated_corrs_et = [cor for cor in aggregated_corrs_et if 'expert' not in cor['col1'] and 'turk' not in cor['col1']]
# sort from highest corr to lowest
aggregated_corrs_et = sorted(aggregated_corrs_et, key=lambda x: x['pearson_corr'], reverse=True)

aggregated_corrs_et

"""Do within feature correlations to see if features correlate with each other"""

aggregated_corrs_features = []
feature_cols = get_non_expert_turk_cols()
for c in feature_cols:
  aggregated_corrs_features.extend(get_corrs_threshold(merged, c, threshold=0.75))

# filter self correlations
aggregated_corrs_features = [cor for cor in aggregated_corrs_features if cor['col1'] != cor['col2']]
# sort from highest corr to lowest
aggregated_corrs_features = sorted(aggregated_corrs_features, key=lambda x: x['pearson_corr'], reverse=True)

aggregated_corrs_features[-5:]

# the list of "our" metrics that have corr >= 0.25
set([(c['col1']) for c in aggregated_corrs_et if 'metric_scores_11' not in c['col1']])

# interesting that the bert scores are not correlated perfectly
get_corr(merged, 'metric_scores_11_bert_score_recall', 'bert_score_recall')

# same with chrf
get_corr(merged, 'metric_scores_11_chrf', 'chrf_metric')

get_corr(merged, 'metric_scores_11_meteor', 'meteor_metric')

