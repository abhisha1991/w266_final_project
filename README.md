# NLP With Deep Learning (W266)

Submission by *Carolina Arriaga, Ayman, Abhi Sharma*

Winter 2021 | UC Berkeley

## ShapSum: A Framework to Predict Human Judgement Multi-Dimensional Quality Scores for Text Summarization

Text summarization is the task of producinga shorter version of a document.  Model per-formance  has  been  compared  amongst  eachother based mainly on their ROUGE score. Themetric has been widely criticized because itonly assesses content selection and does notaccount for other quality metrics such as flu-ency, grammaticality, coherence, consistency,and relevance (Ruder). (Lin, 2004). Combinedscore metrics like BLEND or DPMFcomb in-corporate lexical, syntactic and semantic basedmetrics and achieve high correlation with hu-man judgement  (Yu et  al., 2015) in  the MTand text generation context.  However,  noneof  these  combined  metrics  have  been  testedin  summaries,  and  particularly,  have  movedaway from human scores based on Pyramidand Responsiveness scores. Our findings showthat multiple metrics used in the summarizationfield are predictive of multidimensional qualityevaluations from experts.  We produced foursaturated models using decision trees and thecorresponding surrogate Shapley explanationmodels to measure metric contribution againstfour dimensions of evaluation (fluency,  rele-vance, consistency, coherence). We hope thatour work can be used as a standard evaluationframework  to  compare  summary  quality  be-tween new summarization models

#### Project outputs
1. [Link](https://drive.google.com/drive/folders/1_EzQMxyx_lvsHvgrJs7FoYFALpsZM3Xe?usp=sharing) to Google Drive folder.
2. [Link](https://github.com/abhisha1991/w266_final_project/blob/main/report/ShapSum__A_framework_to_predict_human_judgement_multi_dimensional_qualities_for_text_summarization_.pdf) to paper.
3. [Link](https://docs.google.com/presentation/d/1QM0jkJZ2foetrGy1y6AL8szoAcRdYTnJ8TeHR9dOSR4/edit?usp=sharing) to presentation.

